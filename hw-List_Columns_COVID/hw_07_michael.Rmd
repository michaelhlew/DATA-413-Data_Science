---
title: "DATA-413/613: HW on List Columns and COVID19"
author: "Michael Lewis"
date: "`r Sys.Date()`"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align  = "center",
                      fig.height = 6,
                      fig.width  = 7,
                      cache = FALSE)
```

# Instructions {-}
See .html file

# Scoring Rubric {-}

See .html file

# Load Global and US Confirmed Cases and Deaths Data into a Nested Data Frame
1. Create a variable called `url_in` to store this URL: "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/". 
  - This allows you to directly download the files at the John's Hopkins site:  "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
2. Create a tibble named `df` with a variable called `file_names` with a row for each of the following two file names to be loaded from the URL:
    + time_series_covid19_confirmed_global.csv
    + time_series_covid19_deaths_global.csv
3. Create a variable in the data frame called `url` that puts `url_in` on the front of each file_name to create a complete URL.
4. Use `mutate()` with `map()` to create a list column called `data` with each row holding the downloaded data frame for each file name
5. Add a factor variable `case_type` to `df` with the **unique** portions of the `file_names` as output from a {stringr} function.
6. Remove any columns other than `case_types` and `data` from `df`.
- `df` should have two observations of two variables.

```{r}
suppressMessages(library(tidyverse))
#URL in
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"

#Df with file names
tibble(file_names = c("time_series_covid19_confirmed_global.csv",
                            "time_series_covid19_deaths_global.csv")) -> df
#put URL front of file name
df %>%
  mutate(url = str_c(url_in, file_names, sep = "")) -> df

#mutate/map, list col data with each row holding downloaded data
df %>%
  mutate(data = map(url, ~read_csv(., na = ""))) -> df

#factor var "case_type" / unique portions of the 'file names' stringr

df %>%
  mutate(case_type = as_factor
         (str_extract(file_names, "(?<=(?<=\\d)_).+.(?=_(?=g))")) 
         ) -> df 

#select case_types, data

df %>% 
  select(case_type, data) -> df

head(df) #two observations, two variables

```


# Clean Data  
1. Using a **single call to `map()`**, add only the first 15 names from each of the four data frames to a new variable in `df` called `vars`. Do NOT try to add to the individual data frames. `df` should now have three variables/columns and two observations 
  - We want to eventually combine all the data frames into one data frame so they should have the same column names. 
 - Visually compare them to identify any issues across the rows.

```{r}
df %>%
  mutate(vars = map(data, ~unlist(.)[1:15])) -> df #single map call

head(df) #vars, 15 characters
```


2. Inside a **single call to `mutate()`, make the changes in steps b through e** using {purrr} functions to fix any issues and create consistent data frames, Then use map to do f and g. (should be eight uses of a `map_*` function).  



a. Create a short (4 lines) generic helper function called `fix_names()` which takes three arguments: a data frame, a string pattern, and a string "replacement pattern". It should replace all occurrences of the "string pattern" in the names of the columns in the data frame with the "replacement pattern". Include error checking to ensure the inputs are of the proper class. It should not know anything about the contents of the data frame argument.

```{r}

fix_names <- function(df, string_pattern, replacement) {

stopifnot(is.data.frame(df), is_character(string_pattern), 
is_character(replacement)) #ensures all inputs are of correct class

  #str_replace_all in order to replace all occurrences
  #searching for pattern in df names
str_replace_all(names(df), string_pattern, replacement) -> names(df)
return(df)
}

```


b. Use your function with `map()` to convert `Province/State` to `Province_State` and `Country/Region` to `Country_Region`.
c. Use a {purrr} function to add variable called `Country_State` that unites `Country_Region` and `Province/State` while keeping the original columns and removing `NA`s.
d. Use a {purrr} function to remove the variables for `Lat` and `Long`
e. Use a {purrr} function with `select()` to reorder the variables in each data frame as follows: `Country_Region`, `Country_State`, `Province_State`, and then the remaining data columns.
f. Use `map()` to update the values in `df$vars` with the new first 15 names and show the values to check for consistency across data frames.
g. Use `map()` three times: show how many rows are in each data frame, show many columns are in each data frame, and show the name of the last column in each data frame. The last column should be the most recent date in the data frame as of the date the data was pulled. 
```{r}
#b to e:

df %>%
  mutate(
    #province/state --> province_state & country/region to country_region
    data = map(data, ~fix_names(., "([ey])/", "\\1_")),
         
    data = map(data, ~unite(., "Country_State", #new col name
            c("Country_Region", "Province_State"), #unite region/state
            remove = FALSE, na.rm = TRUE, #keep cols, remove NAs
            sep = "_")),
   
    data = map(data, ~select(., -Lat, -Long)),#remove Lat/Long
    
    #re-order variables
    data = map(data, ~select(., Country_Region, Country_State, Province_State, everything()))) -> df
    

#f
df %>%
  mutate(vars = map(data, ~unlist(.)[1:15])) -> df 

#g
df %>% 
mutate(nrow = map_dbl(data, nrow), #number of rows
       ncol = map_dbl(data, ncol), #number of cols
       last_col = map (df$data, ~tail(names (.x),1))) 

#To show the last date was extracted
df %>% 
mutate(nrow = map_dbl(data, nrow), #number of rows
       ncol = map_dbl(data, ncol), #number of cols
       last_col = map (df$data, ~tail(names (.x),1))) -> last_col_date
#Dates
last_col_date$last_col
                    
```





# Use {purrr} to Tidy Each Data Frame 
1. Use `map()` along with `pivot_longer()` to tidy each data frame and then save the results **to a new tibble** called `df_long` as **its own tibble** (NOT a list column in the `df` tibble).

  - `df` should still have 2 observations with three variables and the data frames in `data` should have 289 rows.
  - `df_long` should have 2 observations with three variables but now the data frames in `data` should have at least 236,856 rows (as of 11/1/2022).

- **As part of the pivot**, 
  - Put the daily totals in a variable called `Daily_Total`.
  - Put the dates in a variable called `Date`. 
  - Use a {lubridate} function *inside the pivot* to ensure `Date` is of class `date`. 
  
```{r}
library(lubridate)
df %>%
  mutate(data = map(data, ~pivot_longer(data = ., cols = contains("/"),
                                       names_to = "Date",
                                       names_transform = list(Date = mdy),
                                      values_to = "Daily_Total"))) -> df_long
                    
                 

nrow(df[[2]][[1]]) #still has 289 rows
nrow(df[[2]][[2]]) #still has 289 rows

nrow(df_long[[2]][[1]]) #296,803 rows in dflong
nrow(df_long[[2]][[2]]) #296,803 rows in dflong
                                
```


2. Use `map` to show how many rows are in each data frame in the `df_long$data` list column.

```{r}
df_long %>% 
  mutate(nrow = map_dbl(data, nrow)) 

#In each df there are ~296k rows

```

3. Use `map` to show the last seven days of data in each data frame for the the United States (`Country_Region == "US"`). Use a sentence to describe what each row represents in each data frame.

Each row in the data frame represents one unique day, in total each data frame contains values for the past week. 

```{r}
df_long %>% 
  mutate(US_filtered = map(data, ~filter(.x, Country_Region == 'US')), #filters down to US
         US_filtered = map(US_filtered, ~tail((.x),7))) -> df_filtered #filters down to last 7 days

df_filtered$US_filtered[1]
df_filtered$US_filtered[2]
remove(df_filtered, last_col_date) #for memory purposes, no longer needed
```


# Add Continents 
1.  Use `map()` to add a new variable called `Continent` to each data frame in `dfr_long$data`.  
  - Hint: use the package {countrycode} to get the continents. If you don't have it already, **use the console** to install. 
  - Then load package {countrycode} and look at help for `countrycode::countrycode`
  - You will get some warning messages about ambiguous values which you will fix in the next step.

    ```{r, countrycode_lib}
    library(countrycode)
  
  #Adding in continent
  df_long %>%
  mutate(data = map(data, ~mutate(., Continent = countrycode(Country_Region,
        origin = "country.name",
        destination = "continent")))
         ) -> df_long
  
  #df_long$data[1] looking at data to confirm
  #df_long$data[2] looking at data to confirm
  
  #Adding in ISO_Code
  df_long %>%
     mutate(data = map(data, ~mutate(., ISO3_code = countrycode(Country_Region,
        origin = "country.name",
        destination = "iso3c")))) -> df_long
  
  #df_long$data[1] looking at data to confirm
  #df_long$data[2] looking at data to confirm
    ```


2. Fix Ambiguous Values for Continents
- Use `map()` with `case_when()` (inside a `mutate()`) to replace the `NA`s due to Antarctica, Diamond Princess, Kosovo, Micronesia, MS Zaandam, Summer Olympics 2020, and Winter Olympics 2022 with the most appropriate continent.
- Use `map()` with `unique()` to confirm six continents in the global data frames 

```{r}
df_long %>%
  mutate(data = map(data, ~mutate(., Continent = case_when(
        Country_Region == "Antarctica" ~ "Americas", #the nearest continent to Antarctica is S. America
        Country_Region == "Diamond Princess" ~ "Asia", #was in Asia during COVID outbreak
        Country_Region == "Kosovo" ~ "Europe", #in Europe
        Country_Region == "Micronesia" ~ "Asia", #Asia-Pacific
        Country_Region == "MS Zaandam" ~ "Americas", #in Argentina/Chile during outbreak
        Country_Region == "Summer Olympics 2020" ~ "Americas", #in Brazil
        Country_Region == "Winter Olympics 2020" ~ "Asia", #in Beijing 
        TRUE ~ Continent)
                ))) -> df_long

#Confirming continents
map(df_long$data, ~unique(.$Continent)) #there are 6

```


# Unnest the Data Frames    
1. Unnest and ungroup the data frames in `df_long$data` and save the results into a new separate data frame called `df_all`. You should now have three distinct objects; `df`, `df_long`, and `df_all`

```{r}
#unnesting
df_long %>%
  unnest(cols = data) %>%
  ungroup() -> df_all #saving to new df 
```


2. Remove the `df` and `df_long` data frames from the global environment.

```{r}
remove(df, df_long) 
```


3. Remove the `vars` variable from `df_all` and save `df_all`.

- `df_all` should have at least 586,000 rows as of 11/1/2022.

```{r}
df_all %>%
  select(-vars) -> df_all

#row check
nrow(df_all)
```


4. Save `df_all` as both a .csv file and a .rds file to a data directory. Compare their file sizes?

```{r}
write_csv(df_all, "data/df_all.csv") #saved a csv file that is 35.8 MB
write_rds(df_all, "data/df_all.rds") #saved a RDS file that is 3.6 MB
```


# Get World Population Data
1.a.  Use `vroom::vroom()` with a relative path to read in the zipped .csv file with World population data for 1950-2100 into its own data frame called `df_pop`.  

  - The data is from the [UN](https://population.un.org/wpp/Download/Standard/CSV/) which uses different country names in many cases from the COVID data. It also uses a different structure for separating countries and territories.  
  - Note: the UN population data is in thousands so it can have fractional values. 
  
- Filter the data to only those rows for 2022 where the scenario variant is "No change" and which have a valid `ISO3_code`,
- Select `Time`, `Location`, `ISO3_code`, `PopTotal`, `PopDensity` and save to `df_pop`.
  - You should have 237 rows remaining out of the 586,092 rows.

```{r}
library(vroom)
vroom("data/WPP2022_TotalPopulationBySex.csv.zip") -> df_pop

df_pop %>%
  filter(Time == 2022) %>%  #filter year 2022
  filter(Variant == "No change") %>% #variant no change
  filter(!is.na(ISO3_code)) %>% #has a valid ISO
  select(Time, Location, ISO3_code, PopTotal, PopDensity) -> df_pop

nrow(df_pop) #correct number of rows

```


b. Show the countries (`Country_Region`) in the Covid data that are not in the population data - Use `ISO3_code`.  How many are there?

```{r}
#all rows from x w/ out match in Y
anti_join(df_all, df_pop) -> df_test

unique(df_test$Country_Region) 

```

There are 7 countries in the COVID data that are not in the population data.

c. Identify the countries in the population data that are not in the covid data. Use `ISO3_code` How many are there?  

```{r}
anti_join(df_pop, df_all) -> df_test
unique(df_test$Location)
```

There are 43 countries in the population data that are not in the COVID data.

d. What is the percentage of the world population contained in the countries not in the covid data?  

```{r}
sum(df_test$PopTotal) -> not_in_covid #sum of pop of countries not in COVID data 
sum(df_pop$PopTotal) -> total_pop #total pop

(not_in_covid / total_pop) * 100 
```

About .3% of the world population is contained in countries not in the COVID data. 

2. Use a {dplyr} join to remove all Locations from `df_pop` that are not in the `df_all` data frame. 

- Add variables to `df_pop` for the rank for each location for population (`rank_p`) and the rank for population density (`rank_d`). 
- Calculate rank using `dplyr:min_rank()` so the country with the largest value is number 1 for that variable. 
- Save to `df_pop`. 

```{r}
#return all rows from x with a match in y.
semi_join(df_pop, df_all) -> df_pop

#rank 
df_pop %>% 
  mutate(rank_p = min_rank(desc(PopTotal)),
         rank_d = min_rank(desc(PopDensity)),
         #adding in full measure, b/c per note population in thousands
         PopTotal_revised = PopTotal*1000) -> df_pop
head(df_pop)
  
```

3. Show the countries with rank 1:10 for  Total Population
- Then show the countries with rank 1:10 for Population Density.

```{r}
df_pop %>% 
  slice_min(rank_p, n = 10) #countries with rank 1:10 for total pop
df_pop %>% 
  slice_min(rank_d, n = 10) #countries with rank 1:10 for total density

```


# Add Population Data to `df_all`
- Use a {dplyr} join to add the data from `df_pop` to `df_all` to create `df_allp` for only those countries in `df_all` even if they are not in `df_pop`.

```{r}
left_join(df_all, df_pop) -> df_allp
glimpse(df_allp)
```


# How many `Country_Regions` have Multiple `Country_States`?
- The data does not treat all countries the same with regard to reporting at the country level or at the province or region level. 
- Some countries are reported with *totals only at the country level* (`Country_Region`), 
- Some countries are reported with *totals only at the state/province level* (`Province_State`), 
- Some countries are reported with *totals for the country and for separate state/provinces* for the country. 
- We can use the `Country States` and `Country Region` variables to figure out what this means.

a.  For each `Country Region` calculate the number of `Country States` for *distinct combinations of `Country States` and `Country Region`* and then, 
  - show in descending order the number of `Country_States`for each `Country_Region` where the number of `Country_States` is greater than 1.

```{r}
df_all %>% 
  select(Country_Region, Country_State) %>% 
  distinct() %>% 
  group_by(Country_Region) %>% 
  summarize(`Number of Distinct Country_State` = n()) %>% 
  filter(`Number of Distinct Country_State` > 1) %>%
  arrange(desc(`Number of Distinct Country_State`))
```

b. For each `Country Region` calculate the number of `Country States` for distinct combinations of `Country States` and `Country Region` where the `Country_Region` does **not have matching entries in `Country_State`** and then,
  - show in descending order the number of `Country_States` for each `Country_Region`, show where the number of `Country_States` is greater than 1.

```{r}
df_all %>% 
  select(Country_Region, Country_State) %>% 
  distinct() %>% #distinct combinations
  filter(Country_Region != Country_State) %>% #does not have matching entries in Country_State
  group_by(Country_Region) %>% 
  summarize(`Number of Distinct Country_State` = n()) %>% 
  filter(`Number of Distinct Country_State` > 1) %>% #greater than 1
  arrange(desc(`Number of Distinct Country_State`)) #desc order
```


c. Explain what the difference between the two results suggests for future analysis of totals for each country represented in `Country_Region`.

This suggests that there is potential duplication of records. Specifically, a country may record all cases nationally, but then also break this national count down by local districts/provinces. For example, New Zealand has a Country_State for the national level, byt also two more Country_State combinations for sub-groups. 

# Analyze Data
1. Use `df_allp` to create a new data frame with data grouped by `Country_Region`, `Continent` `case_type`, `rank_p` and `rank_d` that summarizes the **current totals** and the **totals as a percentage of total population**.
  - Create grand totals for each of the two global case types for both `df_all` and your new data frame and compare them. 
  - Interpret the results. 
  **Check a website to confirm if your numbers are reasonable and show the URL you checked and the numbers.**

```{r}
#Building out first measure
df_allp %>%
 group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>%
 summarise(totalCases = max(Daily_Total)) 

#According to https://covid19.who.int/region/emro/country/af Afghanistan has ~204.5k cases and 7,829 deaths, cases are close enough to result / deaths match exactly 
#According to https://covid19.who.int/region/afro/country/zw Zimbabwe has ~257.893 cases and 5,606 deaths, matches result exactly
     
#Adding in second measure   
df_allp %>%
 group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>%
 summarise(totalCases = max(Daily_Total),          
           total_percent_pop = (totalCases/last(PopTotal_revised)*100)) %>% 
  ungroup() -> cases_percents

```

2. What are the 20 Countries with the most confirmed cases and what is the percentage of their total population affected?

```{r}
cases_percents %>%
group_by(Country_Region, total_percent_pop, totalCases) %>%
filter(case_type == "confirmed") %>%
arrange(desc(totalCases)) %>%
head(20) -> top_20_cases

top_20_cases

```


3. What are the 20 Countries with the most deaths and what is the percentage of their total population affected?

```{r}
cases_percents %>%
group_by(Country_Region, total_percent_pop, totalCases) %>%
filter(case_type == "deaths") %>%
arrange(desc(totalCases)) %>%
head(20) -> top_20_deaths

top_20_deaths

```


4. Describe the results based on the totals with the rankings for total population and population density.

Even though some countries are not particularly dense, they still experienced a significant amount of deaths. This is true for the US, Brazil, Peru, and Russia. As for cases, higher rankings in population generally align with more cases, however, the degree to which cases impacted the total percent of the population varies by country. 


# High Percentage but Low Totals Countries
- Which countries in the top 20 for percentage of population for cases are **Not** in the top 20 for the absolute number of cases.  
- Which countries in the top 20 for percentage of population for deaths are **Not** in the top 20 for the absolute number deaths?
- Describe the results based on the per population results with the rankings for total population and population density.

```{r}
#in top 20 for %, not in absolute
cases_percents %>%
group_by(Country_Region, total_percent_pop, totalCases) %>%
filter(case_type == "confirmed") %>%
mutate(total_percent_pop = total_percent_pop / 1000) %>% #UN data in thousands
arrange(desc(total_percent_pop)) %>%
head(n = 20) -> top_20_cases_percent

data.frame(top_20_cases[1], top_20_cases_percent[1]) %>% 
rename("Country_Region_Absolute" = "Country_Region",
       "Country_Region_Percent" = "Country_Region.1") %>%
mutate(in_percent_not_in_abs = !(Country_Region_Percent %in% Country_Region_Absolute)) %>% 
select(-Country_Region_Absolute) %>%
filter(in_percent_not_in_abs == TRUE) 

#looking at the rankings
data.frame(top_20_cases[1], top_20_cases_percent[1]) %>% 
rename("Country_Region_Absolute" = "Country_Region",
       "Country_Region_Percent" = "Country_Region.1") %>%
mutate(in_percent_not_in_abs = !(Country_Region_Percent %in% Country_Region_Absolute)) %>% 
select(-Country_Region_Absolute) %>%
filter(in_percent_not_in_abs == TRUE) %>% 
select(Country_Region_Percent) %>% 
rename("Country_Region" = "Country_Region_Percent") -> rankings_comparison

left_join(rankings_comparison, top_20_cases_percent) -> rankings_comparison
rankings_comparison %>% 
select(Country_Region, rank_p, rank_d)

```

The countries that are in the percent but not absolute for top 20 cases, tend to have higher density rankings (more density) with relatively lower population rankings (less population). This makes sense because in countries that are smaller, more dense, with less people -- a comparatively small amount of cases will represent a larger chunk of the population. 

```{r}
cases_percents %>%
group_by(Country_Region, total_percent_pop, totalCases) %>%
filter(case_type == "deaths") %>%
mutate(total_percent_pop = total_percent_pop / 1000) %>% #UN data in thousands
arrange(desc(total_percent_pop)) %>%
head(n = 20) -> top_20_deaths_percent


data.frame(top_20_deaths[1], top_20_deaths_percent[1]) %>% 
rename("Country_Region_Absolute" = "Country_Region",
       "Country_Region_Percent" = "Country_Region.1") %>%
mutate(in_percent_not_in_abs = !(Country_Region_Percent %in% Country_Region_Absolute)) %>% 
select(-Country_Region_Absolute) %>%
filter(in_percent_not_in_abs == TRUE) 

#rankings
data.frame(top_20_deaths[1], top_20_deaths_percent[1]) %>% 
rename("Country_Region_Absolute" = "Country_Region",
       "Country_Region_Percent" = "Country_Region.1") %>%
mutate(in_percent_not_in_abs = !(Country_Region_Percent %in% Country_Region_Absolute)) %>% 
select(-Country_Region_Absolute) %>%
filter(in_percent_not_in_abs == TRUE) %>% 
select(Country_Region_Percent) %>% 
rename("Country_Region" = "Country_Region_Percent") -> rankings_comparison
left_join(rankings_comparison, top_20_deaths_percent) -> rankings_comparison
rankings_comparison %>% 
select(Country_Region, rank_p, rank_d)



```

For deaths, the countries that were in percent but not absolute tended to again have comparatively lower population rankings and larger density rankings. Indeed, 10/20 countries had a greater density ranking than their population rankings (more density, lower population). 

# Plotting the Data (Extra Credit)
- Create two plots, one for the number of cases, and one for the number of deaths, showing the changes **over time**.
- Limit to the top 20 `Country_Region` for highest cases and then for  highest deaths 
- Show each country and facet by continent with the same scale for the y axis. 
- Use a log scale for the y axis.
- Interpret each plot with respect to the total cases (or deaths) and the path of cases (or deaths) across and within different continents.

```{r}
#attempt
as_vector(top_20_cases[1]) -> confirmed_20_countries

df_allp %>%
  filter(case_type == "confirmed", Country_Region %in% confirmed_20_countries) %>%
  ggplot(mapping = aes(x = Date, y = Daily_Total)) +
  geom_line(aes(color = Country_Region)) +
  facet_wrap(~Continent) +
  scale_y_log10() +
  theme_bw() +
  ylab("Total Cases") +
  ggtitle("Total Cases Over Time")

as_vector(top_20_deaths[1]) -> deaths_20_countries
df_allp %>%
  filter(case_type == "deaths", Country_Region %in% deaths_20_countries) %>%
  ggplot(mapping = aes(x = Date, y = Daily_Total)) +
  geom_line(aes(color = Country_Region)) +
  facet_wrap(~Continent) +
  scale_y_log10() +
  theme_bw() +
  ylab("Total Deaths") +
  ggtitle("Total Deaths Over Time")
```

